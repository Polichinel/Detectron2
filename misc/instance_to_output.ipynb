{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per default, this is done in the prediction script. But this might be used to change the threshold after training to avoid retraining.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "# from utils import *\n",
    "\n",
    "from collections import Counter\n",
    "# import pandas as pd\n",
    "\n",
    "from xml.etree import ElementTree, ElementInclude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'retinanet_R_101_FPN_3x'\n",
    "threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(img_dir):\n",
    "    \"\"\"Creates a list of classes and corrosponding ints. also a dict to translate\"\"\"\n",
    "\n",
    "    obj_name = []\n",
    "\n",
    "    # Get all objects that have been annotated\n",
    "    for filename in os.listdir(img_dir):\n",
    "        if filename.split('.')[1] == 'xml':\n",
    "            box_path = os.path.join(img_dir, filename)\n",
    "\n",
    "            tree = ElementTree.parse(box_path)\n",
    "            lst_obj = tree.findall('object')\n",
    "\n",
    "            for j in lst_obj:\n",
    "                obj_name.append(j.find('name').text)\n",
    "    \n",
    "    classes = list(sorted(set(obj_name))) # all labesl\n",
    "    classes_int = list(np.arange(0,len(classes))) # corrospoding int\n",
    "    class_to_int = dict(zip(classes,classes_int)) # a dict to translate between them\n",
    "\n",
    "    return(classes, classes_int, class_to_int)\n",
    "\n",
    "def get_img_path(img_dir):\n",
    "\n",
    "    \"\"\"Creates a list of all image paths.\"\"\"\n",
    "\n",
    "    # right now this does not take into account whether the image was anotated or not.\n",
    "    # It also does not handle test or train.\n",
    "\n",
    "    img_path_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for img_name in files:\n",
    "            if img_name.split('.')[1] == 'jpg':\n",
    "                img_path = os.path.join(img_dir, img_name)                \n",
    "                img_path_list.append(img_path)\n",
    "\n",
    "    return(img_path_list)\n",
    "\n",
    "def get_int_to_class():\n",
    "    # This is always the annotatedd folder..\n",
    "    #annotated_img_dir = '/home/projects/ku_00017/data/raw/bodies/OD_images_annotated'  \n",
    "    annotated_img_dir = '/home/simon/Documents/Bodies/data/jeppe/images'\n",
    "    classes, classes_int, class_to_int = get_classes(annotated_img_dir)\n",
    "    int_to_class = dict(zip(classes_int, classes))\n",
    "\n",
    "    return int_to_class\n",
    "\n",
    "\n",
    "def get_output_tX(model_name, threshold):\n",
    "\n",
    "    # Get the instances_list\n",
    "    #instances_list_dir = f'/home/projects/ku_00017/data/generated/bodies/detectron_outputs/{model}/instances_list.pkl'\n",
    "    instances_list_dir = f'/home/simon/Documents/Bodies/data/computerome_outputs/detectron_outputs_test/{model_name}/instances_list.pkl'\n",
    "\n",
    "    with open(instances_list_dir, 'rb') as file:\n",
    "        instances_list = pickle.load(file)\n",
    "\n",
    "    #img_dir = '/home/projects/ku_00017/data/raw/bodies/images_spanner' #full run!!!\n",
    "    img_dir = '/home/simon/Documents/Bodies/data/jeppe/images'\n",
    "\n",
    "    # get images path and int to class dict.\n",
    "    img_path_list = get_img_path(img_dir)\n",
    "    int_to_class = get_int_to_class()\n",
    "\n",
    "    # containers:\n",
    "    output_list = []\n",
    "    all_img_feature_list = [] # to create the slim df, its easier this way...\n",
    "\n",
    "    # number of images to predict\n",
    "    total_count = len(img_path_list)\n",
    "\n",
    "\n",
    "    total_count = 10\n",
    "    # prediction loop\n",
    "    for count, img_path in enumerate(img_path_list[0:total_count]):\n",
    "\n",
    "        instance = instances_list[count]\n",
    "\n",
    "        img_id = img_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "        img_dict = {'img_id': img_id, 'scores': None , 'pred_classes': None}\n",
    "\n",
    "        mask = instance.scores.numpy()>threshold # maybe these scores should be used for more stuff.. lot of information here\n",
    "    \n",
    "        # only save instances above the threshold\n",
    "        img_dict['scores'] = instance.scores.numpy()[mask]\n",
    "        img_dict['pred_classes'] = instance.pred_classes.numpy()[mask]\n",
    "\n",
    "        img_feature_Int_count = dict(Counter(instance.pred_classes.numpy()[mask])) # counting the classes - int encoded\n",
    "        img_dict = {**img_dict, **img_feature_Int_count} # merging counts with other info \n",
    "        \n",
    "        img_feature_list = [int_to_class[i] for i in instance.pred_classes.numpy()[mask]] # convert from int encoded feature to str of feature name\n",
    "        img_feature_count = dict(Counter(img_feature_list)) # count the actual feature name\n",
    "        img_dict = {**img_dict, **img_feature_count} # merging counts name with other info - actual feature\n",
    "\n",
    "        output_list.append(img_dict)\n",
    "        all_img_feature_list += img_feature_list #this will just be a list of all encountered features..\n",
    "\n",
    "        print(f'img id: {img_id}, {count} of {total_count} done...', end = '\\r')  \n",
    "\n",
    "    # get the unique set of features - nice for the thin df.\n",
    "    all_img_feature_list = list(set(all_img_feature_list))    \n",
    "\n",
    "    return output_list, all_img_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list, all_img_feature_list = get_output_tX(model_name, threshold)\n",
    "\n",
    "# pickle configurations and save\n",
    "location = f'/home/projects/ku_00017/data/generated/bodies/detectron_outputs/{model_name}'\n",
    "os.makedirs(location, exist_ok = True)\n",
    "\n",
    "with open(location + f'/output_list_t{int(threshold*100)}.pkl', 'wb') as file:\n",
    "    pickle.dump(output_list, file)\n",
    "\n",
    "with open(location + f'/all_img_feature_list_t{int(threshold*100)}.pkl', 'wb') as file:\n",
    "    pickle.dump(all_img_feature_list, file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7d17cb9a9d1570995e0d0bdc2d11126f4f4f2acc1c9f41118ccdb5e1f5d3dec"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch_env_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
